{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance correlation function\n",
    "def distcorr(X, Y):\n",
    "    X = np.atleast_1d(X)\n",
    "    Y = np.atleast_1d(Y)\n",
    "    if np.prod(X.shape) == len(X):\n",
    "        X = X[:, None]\n",
    "    if np.prod(Y.shape) == len(Y):\n",
    "        Y = Y[:, None]\n",
    "    X = np.atleast_2d(X)\n",
    "    Y = np.atleast_2d(Y)\n",
    "    n = X.shape[0]\n",
    "    if Y.shape[0] != X.shape[0]:\n",
    "        raise ValueError('Number of samples must match')\n",
    "    a = squareform(pdist(X))\n",
    "    b = squareform(pdist(Y))\n",
    "    A = a - a.mean(axis=0)[None, :] - a.mean(axis=1)[:, None] + a.mean()\n",
    "    B = b - b.mean(axis=0)[None, :] - b.mean(axis=1)[:, None] + b.mean()\n",
    "    dcov2_xy = (A * B).sum()/float(n * n)\n",
    "    dcov2_xx = (A * A).sum()/float(n * n)\n",
    "    dcov2_yy = (B * B).sum()/float(n * n)\n",
    "    dcor = np.sqrt(dcov2_xy)/np.sqrt(np.sqrt(dcov2_xx) * np.sqrt(dcov2_yy))\n",
    "    return dcor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e16069bf5047>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "names = ['SWD.csv', 'dataset_2213_cpu_small.csv', 'wine_quality.csv']\n",
    "results_AL = []\n",
    "\n",
    "for i in range(len(names)):\n",
    "    data = pd.read_csv(names[i])\n",
    "    data.head()\n",
    "    data = shuffle(data)\n",
    "    \n",
    "    columns=data.columns\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    scaled_data = pd.DataFrame(scaled_data, columns=columns)\n",
    "    \n",
    "\n",
    "    X = scaled_data.iloc[:,:-1]\n",
    "    Y = scaled_data.iloc[:, -1]\n",
    "    \n",
    "    # preprocessing step\n",
    "    target_std = np.std(Y)\n",
    "    feats_std=[]\n",
    "    for i in range(X.shape[1]):\n",
    "        std=np.std(X.iloc[:,i])\n",
    "        feats_std.append(std-target_std)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(feats_std)):\n",
    "        if feats_std[i]>0:\n",
    "            df = df.append(X.iloc[:,i])\n",
    "        \n",
    "    dataframe = df.transpose()\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    Non_linear= pd.DataFrame()\n",
    "    linear=pd.DataFrame()\n",
    "    m,n=dataframe.shape\n",
    "    thrs=0.7\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            if (i!=j) and (distcorr(dataframe.iloc[:,i],dataframe.iloc[:,j])!=0):\n",
    "                if (distcorr(dataframe.iloc[:,i],dataframe.iloc[:,j])>0) and (distcorr(dataframe.iloc[:,i],dataframe.iloc[:,j])<thrs):\n",
    "                    non_lin_X, non_lin_y =dataframe.iloc[:,i].to_frame(), dataframe.iloc[:,j]\n",
    "                    from sklearn.linear_model import LinearRegression\n",
    "                    model = KernelRidge(alpha=1.0, coef0=1, degree=3, gamma=None, kernel='rbf', kernel_params=None)\n",
    "                    model.fit(non_lin_X, non_lin_y)\n",
    "                    first = model.predict(non_lin_X)\n",
    "                    first_feat_gen = pd.Series(first)\n",
    "                    second_feat_gen = (non_lin_y -(first))\n",
    "                    Non_linear = Non_linear.append(first_feat_gen,ignore_index=True)\n",
    "                    Non_linear = Non_linear.append(second_feat_gen,ignore_index=True)\n",
    "                elif (distcorr(dataframe.iloc[:,i],dataframe.iloc[:,j])>=thrs) and (distcorr(dataframe.iloc[:,i],dataframe.iloc[:,j])<=1):\n",
    "                    lin_X, lin_y =dataframe.iloc[:,i].to_frame(), dataframe.iloc[:,j]\n",
    "                    from sklearn.linear_model import LinearRegression\n",
    "                    model = Ridge(alpha=1.0)\n",
    "                    model.fit(lin_X, lin_y)\n",
    "                    first_feat = model.predict(lin_X)\n",
    "                    \n",
    "                    lin_first_feat = pd.Series(first_feat)\n",
    "                    second_feat = (lin_y -(first_feat))\n",
    "                    linear = linear.append(lin_first_feat, ignore_index=True)\n",
    "                    linear = linear.append(second_feat, ignore_index=True)\n",
    "                    \n",
    "    nonlinear_genereted=linear.T\n",
    "    linear_generated = linear.T\n",
    "    print(\"no. of features generated by nonlinear features :\", nonlinear_genereted.shape[1])\n",
    "    print(\"no. of features generated by linear features:\", linear_generated.shape[1])\n",
    "\n",
    "    Generated_feats = pd.concat([nonlinear_genereted, linear_generated], axis=1)\n",
    "    print(\"Total no. of generated features :\", Generated_feats.shape[1])\n",
    "    \n",
    "    \n",
    "    if Generated_feats.shape[1]>0:\n",
    "        ############################## feature selection methods\n",
    "        # def Randomforest():\n",
    "        # feature selection in 2 steps\n",
    "        # 1st step \n",
    "        from sklearn.feature_selection import RFECV\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        model = RandomForestRegressor()\n",
    "        rfe = RFECV(model, step=1, cv=5)\n",
    "    \n",
    "        select_feats=rfe.fit(Generated_feats,Y)\n",
    "    \n",
    "        n = rfe.n_features_\n",
    "        # get the features selected as dataframe\n",
    "        Data_X = pd.DataFrame()\n",
    "        for i in range(n):\n",
    "            col = Generated_feats.iloc[:,selected_feats_order[i]]\n",
    "            Data_X=Data_X.append(col)\n",
    "        \n",
    "        \n",
    "        one_featsel= Data_X.transpose()\n",
    "\n",
    "        #######2nd step by Std##########################\n",
    "        target_std = np.std(Y)\n",
    "        gen_feats_std=[]\n",
    "\n",
    "        for i in range(one_featsel.shape[1]):\n",
    "            std=np.std(one_featsel.iloc[:,i])\n",
    "            gen_feats_std.append(std-target_std)\n",
    "    \n",
    "    \n",
    "        gen_df = pd.DataFrame()\n",
    "        for i in range(len(gen_feats_std)):\n",
    "            if gen_feats_std[i]>0:\n",
    "                col = one_featsel.iloc[:,i]\n",
    "                gen_df=gen_df.append(col)\n",
    "            \n",
    "        second_featsel = gen_df.transpose()\n",
    "        ##################################################################################\n",
    "        # def LassoLarsCV()\n",
    "        from sklearn.feature_selection import RFECV\n",
    "        from sklearn.linear_model import LassoLarsCV\n",
    "        model = LassoLarsCV()\n",
    "        \n",
    "        rfe = RFECV(model, step=1, cv=5)\n",
    "        select_feats=rfe.fit(Generated_feats,Y)\n",
    "        print(\"Optimal number of features : %d\" % rfe.n_features_)\n",
    "    \n",
    "        selected_feats_order = np.argsort(rfe.grid_scores_)[::-1]\n",
    "    \n",
    "        n = rfe.n_features_\n",
    "        # get the features selected as dataframe\n",
    "        Data_X = pd.DataFrame()\n",
    "        for i in range(n):\n",
    "            col = Generated_feats.iloc[:,selected_feats_order[i]]\n",
    "            Data_X=Data_X.append(col)\n",
    "        \n",
    "        \n",
    "        one_featsel= Data_X.transpose()\n",
    "        \n",
    "        #############2nd step by Std. #############\n",
    "        target_std = np.std(Y)\n",
    "        gen_feats_std=[]\n",
    "\n",
    "        for i in range(one_featsel.shape[1]):\n",
    "            std=np.std(one_featsel.iloc[:,i])\n",
    "            gen_feats_std.append(std-target_std)\n",
    "    \n",
    "    \n",
    "        gen_df = pd.DataFrame()\n",
    "        for i in range(len(gen_feats_std)):\n",
    "            if gen_feats_std[i]>0:\n",
    "                col = one_featsel.iloc[:,i]\n",
    "                gen_df=gen_df.append(col)\n",
    "            \n",
    "        second_featsel = gen_df.transpose()\n",
    "        \n",
    "        ############################################################################################\n",
    "        #Random Forests for Boruta \n",
    "        # def Boruta_RF():\n",
    "        from boruta import BorutaPy\n",
    "        rf_boruta = RandomForestRegressor()\n",
    "        # Perform Boruta\n",
    "        boruta = BorutaPy(rf_boruta, n_estimators='auto', verbose=2)\n",
    "        boruta.fit(Generated_feats,Y)\n",
    "        \n",
    "        one_featsel = Generated_feats.columns[boruta.support_]\n",
    "        \n",
    "        #############2nd step by Std. #############\n",
    "        target_std = np.std(Y)\n",
    "        gen_feats_std=[]\n",
    "\n",
    "        for i in range(one_featsel.shape[1]):\n",
    "            std=np.std(one_featsel.iloc[:,i])\n",
    "            gen_feats_std.append(std-target_std)\n",
    "    \n",
    "    \n",
    "        gen_df = pd.DataFrame()\n",
    "        for i in range(len(gen_feats_std)):\n",
    "            if gen_feats_std[i]>0:\n",
    "                col = one_featsel.iloc[:,i]\n",
    "                gen_df=gen_df.append(col)\n",
    "            \n",
    "        second_featsel = gen_df.transpose()\n",
    "        \n",
    "        ########################################################################################\n",
    "    \n",
    "        \n",
    "        \n",
    "    transformed_X = pd.concat([X, second_featsel], axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    xtrain, xvalid, ytrain, yvalid = train_test_split(transformed_X, Y, test_size = 0.8, random_state = 42)\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.feature_selection import RFECV\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    reg = RandomForestRegressor()\n",
    "    reg.fit(xtrain, ytrain)\n",
    "    y_pred = reg.predict(xvalid)\n",
    "    print('R^2 Training Score: {:.2f} \\nR^2 Validation Score: {:.2f}'.format(reg.score(xtrain, ytrain),\n",
    "                                                                             reg.score(xvalid, yvalid)))\n",
    "    MSE=mean_squared_error(yvalid, y_pred)\n",
    "    \n",
    "    results_AL.append(MSE)\n",
    "    \n",
    "    print(\"mean square error:\", mean_squared_error(yvalid, y_pred))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nle6046\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\nle6046\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\nle6046\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Training Score: 1.00 \n",
      "R^2 Validation Score: 0.97\n",
      "mean square error: 0.032963889760506085\n",
      "R^2 Training Score: 0.72 \n",
      "R^2 Validation Score: 0.24\n",
      "mean square error: 0.7723555207213983\n",
      "R^2 Training Score: 0.88 \n",
      "R^2 Validation Score: 0.32\n",
      "mean square error: 0.6804182397556693\n"
     ]
    }
   ],
   "source": [
    "names = ['dataset_2213_cpu_small.csv','SWD.csv', 'wine_quality.csv']\n",
    "results_org = []\n",
    "\n",
    "for i in range(len(names)):\n",
    "\n",
    "    data = pd.read_csv(names[i])\n",
    "    data.head()\n",
    "    \n",
    "    columns=data.columns\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    scaled_data = pd.DataFrame(scaled_data, columns=columns)\n",
    "    x = scaled_data.iloc[:,:-1]\n",
    "    y = scaled_data.iloc[:, -1]\n",
    "    \n",
    "    from sklearn.feature_selection import RFECV\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size = 0.8, random_state = 42)\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(x_train, y_train)\n",
    "    ypred = model.predict(x_valid)\n",
    "    print('R^2 Training Score: {:.2f} \\nR^2 Validation Score: {:.2f}'.format(model.score(x_train, y_train),\n",
    "                                                                             model.score(x_valid, y_valid)))\n",
    "    mse=mean_squared_error(y_valid, ypred)\n",
    "\n",
    "    results_org.append(mse)\n",
    "    print(\"mean square error:\", mean_squared_error(y_valid, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEWCAYAAAB2X2wCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAX0UlEQVR4nO3dfbRddX3n8ffHYESF8mDutIUEQjVOTSuiXmjHRxCdAdtJbEVNWitYldqKtGo7jdVBiqtqtUvGjulYVAarQkS6bNNObGwVfKiCuSiiIaIxormND5cnsT6A0e/8cXb09OTce/dNzk3Izvu11lk5+7d/Z+/vPvfmc3/nd87ZO1WFJOnAd5/9XYAkaTQMdEnqCANdkjrCQJekjjDQJakjDHRJ6ggDXTrAJPmTJG/b33Xo3sdAP0gluSbJHUnuN8fHVZKHzFf/fSU95yf5XJLvJJlM8t4kD9/ftc2mql5TVc/f33Xo3sdAPwglWQo8HihgxX4tZgSSHLIHD3sT8PvA+cDRwEOBvwN+ZYSljdweHqsOEgb6wek5wLXAZcDZ/Suakfvz+5bPSfKx5v5HmubPJPn3JM9q2l+QZGuS25OsT3JMmyKS/HaSLc0rhY1Jju9b96Yk25PcleT6JI/vW3dhkquSvCvJXcA5TduVSf4mybeTbE4yPs1+lwEvAlZX1Yeq6u6q+m5VvbuqXtf0OaLZ1lSSryR5ZZL79D0n/5rk4iR3JtmW5DFN+/Yk30xydt/+LkvyliT/3NT24REc67ua9Yc2625ratmU5Kebdcc0P4/bm5/PCwa22+r50oHDQD84PQd4d3P7b7sCYDZV9YTm7iOq6rCqek+SJwGvBZ4J/CzwFWDdbNtK8jTgT4BfB8aAjwJX9HXZBJxEb/R8OfDeJIf2rV8JXAUc2RwH9F5trGva1gNvnmb3pwOTVfXJGUr838ARwM8BT6T3nD23b/0vATcCD2rqWwecDDwEeDbw5iSH9fX/TeDVwCLghr6a9/RYdzm7qXNJU8sLge81664AJoFjgLOA1yQ5ve+xbZ8vHSiqyttBdAMeB/wAWNQsfx54Sd/6a4Dn9y2fA3ysb7mAh/Qtvx14fd/yYc32lw7r39fv/cDz+pbvA3wXOH6auu+g94cE4ELgIwPrLwT+pW95OfC9abb1CuDaGZ6jBcDdwPK+tt8Brul7Tr7Yt+7hzXH+dF/bbcBJzf3LgHUDz9EPgSV7cazvau7/NvBx4MSBPkuafRze1/Za4LK5Pl/eDpybI/SDz9nAB6rq1mb5cgamXeboGHqjcgCq6t/phdmxszzueOBNzTTBncDtQHY9LsnLmumYbzXrj6A3ut1l+5Btfr3v/neBQ6eZc76N3quJ6SwCFvYfV3O//5i+0Xf/ewBVNdjWP0L/cb3Nc3Q7veduT491l3cCG4F1SXYkeX2S+zbbvr2qvj3DMbR9vnSAMNAPIknuT29q5IlJvp7k68BLgEckeUTT7TvAA/oe9jOzbHYHvXDetY8H0nvp/2+zPG478DtVdWTf7f5V9fFmDvmPm1qPqqojgW/RC/xd9uY0oR8EFs8wZ3wrvVcZx/e1HcfsxzSTJbvuNFMxRwM79vZYq+oHVfWnVbUceAzwq/Smh3YARyc5fITHoHs5A/3g8jR6L8OX05uzPQl4GL356+c0fW4Afj3JA9L7uOHzBrbxDXrzyrtcDjw3yUnpfQTyNcB1VXVLX5+FzZt3u24LgLcAL0/yC/DjNyGf0fQ/HNgJTAGHJLkA+KkRHD8AVfVF4K+AK5KcmmRXfauSrKmqHwJXAn+W5PDmDcyXAu/ai90+NcnjkiykN5d+XVVtZy+PNclpSR7ePKd30ftD9MNm2x8HXtsc24n0fpaDc/DqEAP94HI28H+r6qtV9fVdN3pvhv1m83L7YuAeesH9DnYPgAuBdzRTJc+sqg8C/xP4W+BrwIOBVQOP2UxvCmLX7blV9T7gz+lNFdwFfA44s+m/kd4c+xfoTRN8n5mnHfbE+fSOey1wJ/Al4NeAf2jWv5jeq5VtwMfo/eG6dC/2dznwKnpTLY+m9yYp7P2x/gy9N0zvArYAH+Ynf3hWA0vpjdbfB7yqqv55L45B93Kp8gIX0nxKchm9T9W8cn/Xom5zhC5JHWGgS1JHOOUiSR3hCF2SOsJAl6SOMNAlqSMMdEnqCANdkjrCQJekjjDQJakjDHRJ6ggDXZI6wkCXpI4w0CWpIwx0SeoIA12SOsJAl6SOaHWF7yRnAG8CFgBvq6rXDaw/jt7lyo5s+qypqg0zbXPRokW1dOnSPalZkg5a119//a1VNTZs3ayB3lx8di3wFGAS2JRkfVXd1NftlcCVVfV/kiwHNtC7luG0li5dysTERMtDkCQBJPnKdOvaTLmcAmytqm1VdQ+wDlg50Kf4yZXKj6B3UVpJ0j7UJtCP5T9ehXyyaet3IfDsJJP0RucvHrahJOcmmUgyMTU1tQflSpKm0ybQM6Rt8Lp1q4HLqmox8FTgnUl223ZVXVJV41U1PjY2dApIkrSH2gT6JLCkb3kxu0+pPA+4EqCqPgEcCiwaRYGSpHbaBPomYFmSE5IsBFYB6wf6fBU4HSDJw+gFunMqkrQPzRroVbUTOA/YCGyh92mWzUkuSrKi6fYy4AVJPgNcAZxTVYPTMpKkedTqc+jNZ8o3DLRd0Hf/JuCxoy1NkjQXflNUkjqi1QhdkmaTDPtA3MycmR0tA13SSEwXzkkM7n3EKRdJ6ggDXZI6wkCXpI4w0CWpIwx0SeoIA12SOsJAl6SOMNAlqSMMdEnqCANdkjrCQJekjjDQJc3J0UcfTZLWN2BO/ZNw9NFH7+ejPDB5ci5Jc3LHHXfM+8m29uTMjXKELkmd0SrQk5yR5OYkW5OsGbL+4iQ3NLcvJLlz9KVKkmYy65RLkgXAWuApwCSwKcn65rJzAFTVS/r6vxh45DzUKkmaQZsR+inA1qraVlX3AOuAlTP0X03vQtGSpH2oTaAfC2zvW55s2naT5HjgBOBDe1+aJGku2gT6sLebp3uLexVwVVX9cOiGknOTTCSZmJqaalujJKmFNoE+CSzpW14M7Jim7ypmmG6pqkuqaryqxsfGxtpXKUmaVZtA3wQsS3JCkoX0Qnv9YKck/xk4CvjEaEuUJLUxa6BX1U7gPGAjsAW4sqo2J7koyYq+rquBdeXlvSVpv2j1TdGq2gBsGGi7YGD5wtGVJUmaK7/6L2lO6lU/BRceMf/70JwZ6JLmJH961z45l4uv+efOc7lIUkcY6JLUEQa6JHWEgS5JHWGgS1JHGOiS1BEGuiR1hIEuSR1hoEtSRxjoktQRBrokdYSBLkkdYaBLUkcY6JLUEQa6JHWEgS5JHdEq0JOckeTmJFuTrJmmzzOT3JRkc5LLR1umJGk2s16xKMkCYC3wFGAS2JRkfVXd1NdnGfBy4LFVdUeS/zRfBUuShmszQj8F2FpV26rqHmAdsHKgzwuAtVV1B0BVfXO0ZUqSZtMm0I8FtvctTzZt/R4KPDTJvya5NskZwzaU5NwkE0kmpqam9qxiSdJQbQI9Q9oGrxB7CLAMOBVYDbwtyZG7Pajqkqoar6rxsbGxudYqSZpBm0CfBJb0LS8Gdgzp8/dV9YOq+jJwM72AlyTtI20CfROwLMkJSRYCq4D1A33+DjgNIMkielMw20ZZqCRpZrMGelXtBM4DNgJbgCuranOSi5KsaLptBG5LchNwNfBHVXXbfBUtSdpdqganw/eN8fHxmpiY2C/7lrTnkjDfubEv9nGgSnJ9VY0PW+c3RSWpIwx0SeoIA12SOsJAl6SOMNAlqSMMdEnqCANdkjrCQJekjjDQJakjDHRJ6ggDXZI6wkCXpI4w0CWpIwx0SeoIA12SOsJAl6SOMNAlqSMMdEnqiFaBnuSMJDcn2ZpkzZD15ySZSnJDc3v+6EuVJM3kkNk6JFkArAWeAkwCm5Ksr6qbBrq+p6rOm4caJUkttBmhnwJsraptVXUPsA5YOb9lSZLmqk2gHwts71uebNoGPT3JjUmuSrJk2IaSnJtkIsnE1NTUHpQrSZpOm0DPkLYaWP4HYGlVnQj8C/COYRuqqkuqaryqxsfGxuZWqSRpRm0CfRLoH3EvBnb0d6iq26rq7mbxrcCjR1OeJKmtNoG+CViW5IQkC4FVwPr+Dkl+tm9xBbBldCVKktqY9VMuVbUzyXnARmABcGlVbU5yETBRVeuB85OsAHYCtwPnzGPNkqQhUjU4Hb5vjI+P18TExH7Zt6Q9l4T5zo19sY8DVZLrq2p82Dq/KSpJHWGgS1JHGOiS1BEGuiR1hIEuSR1hoEtSRxjoktQRBrokdYSBLkkdYaBLUkcY6JLUEQa6JHWEgS5JHWGgS1JHGOiS1BEGuiR1hIEuSR3RKtCTnJHk5iRbk6yZod9ZSSrJ0KtpSJLmz6yBnmQBsBY4E1gOrE6yfEi/w4HzgetGXaQkaXZtRuinAFuraltV3QOsA1YO6fdq4PXA90dYnySppTaBfiywvW95smn7sSSPBJZU1T+OsDZJ0hy0CfQMafvx5biT3Ae4GHjZrBtKzk0ykWRiamqqfZWSpFm1CfRJYEnf8mJgR9/y4cAvAtckuQX4ZWD9sDdGq+qSqhqvqvGxsbE9r1qStJs2gb4JWJbkhCQLgVXA+l0rq+pbVbWoqpZW1VLgWmBFVU3MS8WSpKFmDfSq2gmcB2wEtgBXVtXmJBclWTHfBUqS2jmkTaeq2gBsGGi7YJq+p+59WZKkufKbopLUEQa6JHWEgS5JHWGgS1JHGOiS1BEGuiR1RKuPLUpSv2TYGUFG56ijjprX7XeVgS5pTqpq9k59ksz5MdozTrlIUkcY6JLUEQa6JHWEgS5JHWGgS1JHGOiS1BEGuiR1hIEuSR1hoEtSRxjoktQRrQI9yRlJbk6yNcmaIetfmOSzSW5I8rEky0dfqiRpJrMGepIFwFrgTGA5sHpIYF9eVQ+vqpOA1wNvHHmlkqQZtRmhnwJsraptVXUPsA5Y2d+hqu7qW3wg4Jl4JGkfa3O2xWOB7X3Lk8AvDXZK8iLgpcBC4EnDNpTkXOBcgOOOO26utUqSZtBmhD7sxMe7jcCram1VPRj4Y+CVwzZUVZdU1XhVjY+Njc2tUknSjNoE+iSwpG95MbBjhv7rgKftTVGSpLlrE+ibgGVJTkiyEFgFrO/vkGRZ3+KvAF8cXYmSpDZmnUOvqp1JzgM2AguAS6tqc5KLgImqWg+cl+TJwA+AO4Cz57NoSdLuWl2Crqo2ABsG2i7ou//7I65LkjRHflNUkjrCQJekjjDQJakjDHRJ6ggDXZI6wkCXpI4w0CWpIwx0SeoIA12SOsJAl6SOMNAlqSMMdEnqCANdkjrCQJekjjDQJakjDHRJ6ggDXZI6wkCXpI5oFehJzkhyc5KtSdYMWf/SJDcluTHJB5McP/pSJUkzmTXQkywA1gJnAsuB1UmWD3T7NDBeVScCVwGvH3WhkqSZtRmhnwJsraptVXUPsA5Y2d+hqq6uqu82i9cCi0dbpiRpNm0C/Vhge9/yZNM2necB7x+2Ism5SSaSTExNTbWvUpI0qzaBniFtNbRj8mxgHHjDsPVVdUlVjVfV+NjYWPsqJUmzOqRFn0lgSd/yYmDHYKckTwZeATyxqu4eTXmSpLbajNA3AcuSnJBkIbAKWN/fIckjgb8GVlTVN0dfpiRpNrMGelXtBM4DNgJbgCuranOSi5KsaLq9ATgMeG+SG5Ksn2ZzkqR50mbKharaAGwYaLug7/6TR1yXJGmO/KaoJHWEgS5JHWGgS1JHGOiS1BEGuiR1hIEuSR1hoEtSRxjoktQRBrokdYSBLkkdYaBLUkcY6JLUEQa6JHWEgS5JHWGgS1JHGOiS1BEGuiR1RKtAT3JGkpuTbE2yZsj6JyT5VJKdSc4afZmSpNnMGuhJFgBrgTOB5cDqJMsHun0VOAe4fNQFSpLaaXNN0VOArVW1DSDJOmAlcNOuDlV1S7PuR/NQoySphTZTLscC2/uWJ5s2SdK9SJtAz5C22pOdJTk3yUSSiampqT3ZhCRpGm0CfRJY0re8GNixJzurqkuqaryqxsfGxvZkE5KkabQJ9E3AsiQnJFkIrALWz29ZkqS5mjXQq2oncB6wEdgCXFlVm5NclGQFQJKTk0wCzwD+Osnm+SxakrS7Np9yoao2ABsG2i7ou7+J3lSMJGk/8ZuiktQRBrokdYSBLkkdYaBLUkcY6JLUEQa6JHWEgS5JHWGgS1JHGOiS1BEGuiR1hIEuSR1hoEtSRxjoktQRrc62qH3swiP20X6+tW/2o4NCMuziZjOvq9qji59pGgb6vZFBqwOQ4bz/OeUiSR1hoEtSRxjoktQRrQI9yRlJbk6yNcmaIevvl+Q9zfrrkiwddaGSpJnNGuhJFgBrgTOB5cDqJMsHuj0PuKOqHgJcDPz5qAuVJM2szQj9FGBrVW2rqnuAdcDKgT4rgXc0968CTs9Mn2GSJI1cm0A/FtjetzzZtA3tU1U7gW8BDxrcUJJzk0wkmZiamtqziiVJQ7UJ9GEj7cEPnLbpQ1VdUlXjVTU+NjbWpj5JUkttvlg0CSzpW14M7Jimz2SSQ4AjgNtn2uj1119/a5KvzKFWzWwRcOv+LkIawt/N0Tp+uhVtAn0TsCzJCcC/AauA3xjosx44G/gEcBbwoZrla2NV5RB9hJJMVNX4/q5DGuTv5r4za6BX1c4k5wEbgQXApVW1OclFwERVrQfeDrwzyVZ6I/NV81m0JGl38fwL3eAoSPdW/m7uO35TtDsu2d8FSNPwd3MfcYQuSR3hCF2SOsJA30eS/FqSSvLzLfr+QZIHtOh3S5JFo6lQ0oHOQN93VgMfo90ngP4AmDXQR605b49Ekg1Jjmxuv9fXfmqSfxzRPk5N8piWfT+T5IqBtsuSnDWKWrrCQN8HkhwGPJbeScxWNW3/4T9GkjcnOSfJ+cAxwNVJrm7WrU7y2SSfSzLjic+SPDDJpUk2Jfl0kpVN+9IkH03yqeb2mL46rk5yOfDZpt+WJG9NsjnJB5Lcfz6eF917VdVTq+pO4Ejg92brv4dOBWYN9CQPo5dVT0jywHmqpRMM9H3jacA/VdUXgNuTPGq6jlX1l/S+iXtaVZ2W5Bh6Z698EnAScHKSp82wr1fQ+2LXycBpwBua/wTfBJ5SVY8CngX8Zd9jTgFeUVW7zqK5DFhbVb8A3Ak8fe6HrHuzJP+jGTyQ5OIkH2run57kXX3Tea8DHpzkhiRvaB5+WJKrknw+ybt3nYiveeynm8HHpUnu17T/eGowyXiSa5pTbL8QeEmz7cfPUO5vAO8EPgCsGPmT0SEG+r6xmt5ZKmn+XT2Hx54MXFNVU82Jz94NPGGG/v8VWJPkBuAa4FDgOOC+wFuTfBZ4L71TIe/yyar6ct/yl6vqhub+9cDSOdSrA8NHgF0hOk4vpO8LPA74aF+/NcCXquqkqvqjpu2R9KYFlwM/Bzw2yaHAZcCzqurh9L60+LvT7byqbgHeAlzcbPuj0/WlNwB5D3AFc/u/c9DxItHzLMmD6I2ufzFJ0fu2bdE7XUL/H9RDp9vEXHcJPL2qbh6o40LgG8Ajmv1+v2/1dwa2cXff/R8CTrl0z/XAo5McTu/n/Sl6wf544Hzg5TM89pNVNQnQDByWAt+mNxD4QtPnHcCLgP+1N0UmORmYqqqvJJkELk1yVFXdsTfb7SpH6PPvLOBvqur4qlpaVUuAXaPh5c3Vno4ATu97zLeBw5v71wFPTLKoedNyNfDhGfa3EXhx38vgRzbtRwBfq6ofAb9F7w+LDlJV9QPgFuC5wMfpjcpPAx4MbJnl4YN/8A9h5oHHTn6SNdMNXKazGvj5JLcAXwJ+CqcAp2Wgz7/VwPsG2v6W3rzglcCN9KZRPt23/hLg/Umurqqv0RstXQ18BvhUVf19X98bk0w2tzcCr6Y3vXJjks81ywB/BZyd5Frgoew+KtfB5yPAHzb/fpTenPYNAyfW6x9czOTzwNIkD2mWf4ufDDxuAR7d3O8P4xm3neQ+wDOAE5vB0FJ6F9Nx2mUaflNUOkglOR34J+DIqvpOki8Ab6mqNzYj4vGqurX5BNSJwPuB/wf8YVX9arONN9M7Sd9lzfb+gt6IfRPwu1V1d/OG59vpTfld12z31CQPpXeFsx8BLx6cR09yKvC6qvrlvrYF9E7X/SjgtcB/B77XrN5eVf9lxE/TAcVAl6SOcMpFkjrCT7lI2u+SvILefHm/91bVn+2Peg5UTrlIUkc45SJJHWGgS1JHGOiS1BEGuiR1hIEuSR3x/wF+qgx/PhwmpAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "label = ['AutoLearn', 'without_AL']\n",
    "fig = plt.figure()\n",
    "fig.suptitle('AutoLearn Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results_AL, positions=[1])\n",
    "plt.boxplot(results_org, positions=[2])\n",
    "ax.set_xticklabels(label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
